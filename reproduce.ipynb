{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64daa581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torch_geometric.nn import to_hetero\n",
    "from torch_geometric.transforms import Compose, ToUndirected\n",
    "from torch_geometric.loader import NeighborLoader, LinkNeighborLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "\n",
    "# project-specific\n",
    "import lib\n",
    "from lib.model import SupervisedNodePredictions, SupervisedEdgePredictions, train_node_readout, make_gae, make_gmae, Readout, test_node_readout, get_x_dict, GraphSAGE, pretrain_gmae, train_edge_readout, test_edge_readout\n",
    "\n",
    "from lib.dataset import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e24878",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "root_path = 'OGBN-MAG/'\n",
    "transform = Compose([ToUndirected(merge=False)])\n",
    "preprocess = 'metapath2vec'\n",
    "data = lib.dataset.load_data(root_path, transform=transform, preprocess=preprocess)\n",
    "\n",
    "train_data = data.subgraph({ # used for the unsupervised part\n",
    "    \"paper\": data[\"paper\"].train_mask.nonzero(as_tuple=False).view(-1)\n",
    "})\n",
    "num_classes = int(data[\"paper\"].y.max()) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a844420",
   "metadata": {},
   "source": [
    "Pretrain the unsupervised encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ec4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = pretrain_gmae(train_data)\n",
    "torch.save(encoder.state_dict(), \"gmae_encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf894384",
   "metadata": {},
   "source": [
    "Run the trained encoder on the full data for training the node classification and edge prediction readout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a66c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_loader(d):\n",
    "    x_dict = get_x_dict(d)\n",
    "    x_dict = {k: v.to(device) for k, v in x_dict.items()}\n",
    "    with torch.no_grad():\n",
    "        z_dict = encoder(x_dict, d.edge_index_dict)\n",
    "    z_paper = z_dict[\"paper\"]\n",
    "    z_paper = z_paper.detach().cpu()\n",
    "    y_paper = d[\"paper\"].y.cpu()\n",
    "    torchdataset = torch.utils.data.TensorDataset(z_paper, y_paper)\n",
    "    return torch.utils.data.DataLoader(\n",
    "        torchdataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "train_loader = dataset_to_loader(train_data)\n",
    "val_loader   = dataset_to_loader(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11da3e52",
   "metadata": {},
   "source": [
    "Train node readout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab3d952",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "readout = Readout(num_classes).to(device)\n",
    "for epoch in range(5):\n",
    "    loss = train_node_readout(readout, train_loader)\n",
    "    acc  = test_node_readout(readout, val_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val Acc: {acc:.4f}\")\n",
    "\n",
    "torch.save(readout.state_dict(), \"gmae_node_classification_readout\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64691386",
   "metadata": {},
   "source": [
    "Train edge readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c443864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_train_mask = data[\"paper\"].train_mask\n",
    "paper_test_mask  = data[\"paper\"].val_mask\n",
    "edge_type = (\"paper\", \"has_topic\", \"field_of_study\")\n",
    "edge_index = data[edge_type].edge_index   \n",
    "paper_idx = edge_index[0]               \n",
    "fos_idx = edge_index[1]              \n",
    "train_edge_mask = paper_train_mask[paper_idx]\n",
    "test_edge_mask = paper_test_mask[paper_idx]\n",
    "train_edge_index = edge_index[:, train_edge_mask]\n",
    "test_edge_index  = edge_index #[:, test_edge_mask] allowed to see all edges during inference \n",
    "\n",
    "x_dict = get_x_dict(data)\n",
    "with torch.no_grad():\n",
    "    z_dict = encoder(x_dict, data.edge_index_dict)\n",
    "z_paper = z_dict[\"paper\"].detach()            \n",
    "z_fos   = z_dict[\"field_of_study\"].detach()  \n",
    "readout = Readout(1) # single out channel -- probability\n",
    "\n",
    "def edge_index_to_loader(edge_index, z_paper, z_fos, batch_size=1024):\n",
    "    pos_edge_index = edge_index\n",
    "    num_pos = pos_edge_index.size(1)\n",
    "    num_paper = z_paper.size(0)\n",
    "    num_fos   = z_fos.size(0)\n",
    "    neg_edge_index = negative_sampling(\n",
    "        pos_edge_index,\n",
    "        num_nodes=(num_paper, num_fos),\n",
    "        num_neg_samples=num_pos,\n",
    "    )\n",
    "    z_src_pos = z_paper[pos_edge_index[0]]\n",
    "    z_dst_pos = z_fos[pos_edge_index[1]]  \n",
    "    z_src_neg = z_paper[neg_edge_index[0]]\n",
    "    z_dst_neg = z_fos[neg_edge_index[1]]  \n",
    "    z_src = torch.cat([z_src_pos, z_src_neg], dim=0)\n",
    "    z_dst = torch.cat([z_dst_pos, z_dst_neg], dim=0)\n",
    "    y = torch.cat([\n",
    "        torch.ones(num_pos, dtype=torch.float32),\n",
    "        torch.zeros(num_pos, dtype=torch.float32),\n",
    "    ], dim=0)\n",
    "    dataset = TensorDataset(z_src, z_dst, y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(\"building edge datasets...\")\n",
    "train_loader = edge_index_to_loader(train_edge_index, z_paper, z_fos)\n",
    "test_loader  = edge_index_to_loader(test_edge_index,  z_paper, z_fos)\n",
    "\n",
    "print(\"training edge predictor...\")\n",
    "for epoch in range(2):\n",
    "    loss = train_edge_readout(readout, train_loader)\n",
    "    acc  = test_edge_readout(readout, test_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Test Acc: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2614cab",
   "metadata": {},
   "source": [
    "Train supervised versions of the network for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_type = \"paper\"\n",
    "data_inductive = lib.dataset.to_inductive(data.clone(), target_type)\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data_inductive,\n",
    "    input_nodes=(target_type, data_inductive[target_type].train_mask),\n",
    "    num_neighbors=[15, 10],\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    input_nodes=(target_type, data[target_type].val_mask),\n",
    "    num_neighbors=[15, 10],\n",
    "    batch_size=2048,\n",
    ")\n",
    "\n",
    "hidden_dim = 128  # common dim after projection (and GNN input dim)\n",
    "\n",
    "# GNN expects the post-encoder dim as input\n",
    "model = GraphSAGE(in_channels=hidden_dim, hidden_channels=hidden_dim)\n",
    "model = to_hetero(model, data_inductive.metadata(), aggr='sum')\n",
    "model.num_classes = num_classes\n",
    "model.output_dim = hidden_dim\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "pipeline = SupervisedNodePredictions(model=model, device=device, optimizer=None, target_type=target_type)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(pipeline.classifier.parameters()), lr=0.003)\n",
    "pipeline.optimizer = optimizer\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss = pipeline.train(train_loader)\n",
    "    acc = pipeline.test(val_loader)\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Val Acc: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_edge_type = ('paper', 'has_topic', 'field_of_study')\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data_inductive,\n",
    "    num_neighbors=[15, 10],\n",
    "    edge_label_index=(target_edge_type, data_inductive[target_edge_type].edge_index),\n",
    "    neg_sampling_ratio=1.0,\n",
    "    batch_size=2048,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_loader = LinkNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[15, 10],\n",
    "    edge_label_index=(target_edge_type, data[target_edge_type].edge_index),\n",
    "    neg_sampling_ratio=1.0,\n",
    "    batch_size=2048,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "hidden_dim = 128  # common dim after projection (and GNN input dim)\n",
    "\n",
    "# GNN expects the post-encoder dim as input\n",
    "model = GraphSAGE(in_channels=hidden_dim, hidden_channels=hidden_dim)\n",
    "model = to_hetero(model, data_inductive.metadata(), aggr='sum')\n",
    "\n",
    "print(f'Running on {device}')\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "pipeline = SupervisedEdgePredictions(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    target_edge_type=target_edge_type\n",
    ")\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss = pipeline.train(train_loader)\n",
    "    acc, auroc, auprc = pipeline.test(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Acc: {acc:.4f} | AUROC: {auroc:.4f} | AUPRC: {auprc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
